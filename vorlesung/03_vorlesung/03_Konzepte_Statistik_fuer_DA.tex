
\section{Konzept der Maximum-Likelihood-Methode zum Lösen inverser Probleme}

Bei der Messdatenanalyse geht es um die Schätzung von physikalischen Größen, die
indirekt über das Messen anderer Größen, direkter Messgrößen, ermittelt werden.
Die Aufgabe der Messtechnik lässt sich auch beschreiben als die Bestimmung
des Wertes von physikalischen Größen durch Messverfahren, die auf physikalischen Prinzipien
basieren. Die von einem Sensorsystem angezeigten Größen sind dabei
im allgemeinem andere Größen als diejenigen, die zu messen sind.

Wir hatten in der ersten Vorlesung zur Verdeutlichung der Aufgabenstellung
aus den einem Messsystem direkt zugänglichen Größen die gesuchten physikalischen
Größen zu gewinnen das Beispiel \glqq Beugung am Gitter\grqq ~betrachtet:
\begin{quote}
Ein Gitter wird mit kohärentem Licht beleuchtet. Das transmittierte Licht fällt auf eine CCD-Kamera, die
die Intensitäten in Abhängigkeit von der Position auf dem CCD-Chip aufnimmt. Es gibt dabei $N = 3$ direkte Größen:
zwei Ortskoordinaten $(x, y)$ auf dem CCD und der dazugehörige Intensitätswert $I$. Die Anzahl der CCD-Pixel ist die
Anzahl $J$ der Beobachtungen, $(x_1, y_1, I_1), \dots, (x_J, y_J, I_J)$.

Die gesuchte Information ist die Gitterkonstante $g$ und eventuell auch noch die
Breite der Spalte $b$. Dabei sind die Gitterkonstante $g$ und Breite der Spalte $b$ 
die indirekten Messgröße. 

Zum Modell gehören die physikalischen Gesetze der Fraunhofer-Beugung, zudem auch weitere Größen,
wie die Wellenlänge der Beleuchtung, der Abstand zwischen CCD und dem zu untersuchenden Gitter,
der groß genug sein muss, damit die Gesetze der Fernfeldoptik gelten und so weiter.
Um aus den Abständen der Intensitätsmaxima auf den Abstand der Spalte zu schließen,
werden die Zusammenhänge des Beugungphänomens der Wellenoptik gebraucht.
\end{quote}

Allgemein gibt es zwei Blickrichtungen, die messtechnische Aufgabe zu betrachten,
\begin{itemize}
\item als Modell von der Physik des Messprinzips gemeinsam mit dem statistischen
Modell, dass die Größen Zufallsgrößen sind,
\item als inverses Problem.
\end{itemize}
Ein Modell wird dargestellt durch eine Vorstellung darüber, wie die
indirekten Messgrößen $Y_m$ mit den direkten Messgrößen $X_i$ verknüpft sind:
\begin{equation}
(Y_1, \dots, Y_M) \xrightarrow{\mathrm{Modell}} (X_1, \dots, X_N)
\label{forwardModel}
\end{equation} 
\begin{figure}
\begin{center}
\includegraphics[width=0.8\textwidth, angle = 0]{03_vorlesung/media/Vorl3_Modell1.pdf}
\end{center}
\caption{Modellbildung zur Gewinnung indirekter Messgrößen aus direkten Messgrößen}
\end{figure}

Ein Messvorgang liefert Beobachtungen zu den direkten Messgrößen.
Die wahren Werte der indirekten Größen bleiben verborgen. Die
indirekten Größen können nur geschätzt werden, oftmals auch nur approximiert werden,
weil die Modelle den physikalischen Sachverhalt nur annähernd beschreiben;
denn die Realität ist deutlich komplexer und wird von vielfältigen Einflussfaktoren
bestimmt. Die approximierenden und zufällig streuenden Größen, die die indirekten Messgrößen
repräsentieren, nennen wir \textsl{Modellparameter}.
Die Abweichungen der Modellparameter entstehen also zum einen
durch vereinfachende Modellannahmen und zum anderen durch zufällige Einflüsse wie das
thermische Rauschen von Elektronik oder Vibrationen im Laborraum.

Als gemeinsamen Bezeichner für Modellparameter wählen wir im folgenden
$\mathbf{p} = (P_1, \dots, P_M)$.
Der Buchstabe $\mathbf{p}$ steht hier einfach nur für den Anfangbuchstaben
von dem Begriff Parameter und der Fettdruck weist darauf hin, dass es ein Vektor mit vielen
Einzelparametern sein kann und dient ferner dazu, das Symbol von dem für die Wahrscheinlichkeitsdichte
zu unterscheiden. Diese wird mit $p$ für den Anfangsbuchstaben von \textsl{probability} bezeichnet.
Für die einzelnen Parameter $P_m$ haben wir den Großbuchstaben gewählt, um die Unterscheidung zur
Wahrscheinlichkeitsdichtefunktion zu haben, sowie in Anlehnung an die Konvention Großbuchstaben
$X_i$ und $Y_m$ für die Messgrößen zu verwenden.
\begin{equation}
P_1 \approx Y_1, \dots, P_M \approx Y_M
\end{equation}
Der Schätzvorgang wird als \textsl{Lösen eines inversen Problems} interpretiert.
\begin{equation}
(X_1, \dots, X_N) \xrightarrow{\mathrm{inverses \; Problem}} (Y_1, \dots, Y_M)
\label{inverseProblem}
\end{equation}

Während der ersten Vorlesung vor zwei Wochen wurde Ihnen das Konzept der
\textsl{Maximum-Likelihood}-Methode vorgestellt, aus
der die Methode der kleinsten Residuenquadratsumme hervorgeht. Die Wahrscheinlichkeit,
dass ein Messwert um den Wert $\varepsilon$ von dem geschätzten Modell abweicht, folgt
einer Normalverteilung. Mit anderen Worten kann man auch sagen, dass
die Verteilung der Residuen eine Gaußverteilung ist.
Die Begriffe Gaußverteilung und Normalverteilung verwenden wir synonym.
\begin{equation}
p(\varepsilon | \theta_1,\dots,\theta_M, \sigma) \; = \; \frac{1}{\sigma \sqrt{2 \pi}}
e^{-\frac{1}{2} \left(\frac{\varepsilon}{\sigma}\right)^2}
\label{Maximumlikelihood1}
\end{equation}
Die Symbolik $p(\varepsilon | \theta_1,\dots,\theta_M, \sigma)$ wird gesprochen:
\begin{quote}
Wahrscheinlichkeit $p$ des Eintretens des Ereignises $\varepsilon$
gegeben die Parameter $\theta_1,\dots,\theta_M$ und $\sigma$.
\end{quote}
Der Sprachgebrauch \glqq Eintretens des Ereignises $\varepsilon$\grqq ~stellt die
Sprechweise der Statistik dar. In den angewandten Wissenschaften, Messtechnik,
Elektrotechnik, etc.\ spricht man von der Wahrscheinlichkeit, dass die Messgröße
oder hier die Abweichung der Messgröße vom Modell einen Wert $\varepsilon$ annimmt.

Vor einer Woche wurden Sie mit der Regressionsrechnung vertraut gemacht, die
eine spezielle Anwendung der Maximum-Likelihood-Methode darstellt, bei der
Größen beteiligt sind, die keine Zufallsgrößen darstellen, die Regressoren.
Die Residuen und entsprechend die Regressanden sind die Zufallsgrößen,
für die die in Gl.~(\ref{Maximumlikelihood1}) formulierte Wahrscheinlichkeitsdichte
angenommen wird.
Diese Modellannahme, dass die \textsl{Residuen} als normalverteilt angenommen werden,
hatten wir Vorl.~2 wie folgt formuliert:
\begin{quote}
Die abhängigen Größen $Y$, d.h.\ die \textsl{Regressanden} streuen und ihre Residuen sind
	normalverteilt mit Erwartungswert $E(\varepsilon) = 0$ und Varianz $\mathrm{Var}(\varepsilon) = \sigma^2$. 
	Die Residuen sind \textsl{unabhängig und identisch verteilt}, kurz u.i.v.
	\begin{equation}
	\varepsilon \; \overset{u.i.v.}{\sim} \; \mathcal{N}(0,\sigma) .
	\label{Resinormalverteilt}
	\end{equation}
\end{quote}
Ein Residuum der linearen Regression mit $Y$ als Regressand und $X$ als Regressoren
hat folgende Gestalt
\begin{equation}
\varepsilon_j \; = \; Y_j \; - \; \sum\limits_{i=1}^{M} \theta_i \, X_{i,j}
\end{equation}
wobei der Bezeichner $Y$ der Regressionsrechnung die direkte Messgröße ist und die
Regressoren ebenfalls zu den direkten Größen gehören, jedoch nicht als Zufallsgrößen mit
Streuung, sondern mit vorgegebenen, deterministischen Werten.

Ein Residuum nach der Methode der kleinsten Quadrate für ein Modell mit genau nur einer
einzigen Zufallsgröße $X$ mit einem Modellparameter $\mu$ ist einfach
\begin{equation}
\varepsilon_j \; = \; X_j \, - \, \mu .
\label{oneQuantityOnly1}
\end{equation}

Ein Residuum nach der Methode der kleinsten Quadrate für ein Modell ohne Regressoren,
also mit allen beteiligten Größen als Zufallsgrößen, lässt sich allgemein nicht mit
einem Ansatz darstellen, in dem die Modellparameter linear sind. Bereits bei einer
Geraden, für die sowohl die Abzissengröße $X_1$ als auch die Ordinatengröße $X_2$ streut,
ist der Ansatz nichtlinear. Der Modellparameter Steigung der Geraden ist der Tangenz des
Winkels $\alpha$ der Geraden relativ zur Abzisse. Der zweite Modellparameter
ist der Abstand $d$ der Geraden vom Koordinatenursprung. Das Residuum $\varepsilon_j$ stellt den
Abstand des $j$-ten Messpunktes $(X_{1,j}, X_{2,j})$ zum Modell dar, siehe Abb.~\ref{ResiduenVarianzen}.
\begin{equation}
\varepsilon_j \; = \; 
\left(\begin{array}{c} X_{1,j}\\ X_{2,j}\end{array}\right) \cdot
\left(\begin{array}{c} -\sin(\alpha)\\ \cos(\alpha)\end{array}\right) \; - \; d .
\label{TLSgerade}
\end{equation}
Bei der Lösung von inversen Problemen, bei denen im Gegensatz zur linearen
Regression eine nichtlineare Verknüpfung der Modellparameter vorliegt, lassen
sich die Parameter nicht mehr durch Lösen eines linearen Gleichungssystems bestimmen.
Die Schätzung von Modellparametern besteht dann darin, die Modellparameter auszuprobieren,
d.h.\ viele unterschiedliche Werte vorzugeben, und das Ergebnis der 
Modellrechnungen (\ref{forwardModel2}) mit den beobachteten Werten zu vergleichen, solange,
bis das Ergebnis \glqq gut zu den beobachteten Werten passt\grqq. Numerisch dienen
dazu entsprechende Optimierungsverfahren.
\begin{equation}
(P_1, \dots, P_M) \xrightarrow{\mathrm{Modell}} (X_{\mathrm{Modell},1,j}, \dots, X_{\mathrm{Modell},N,j})
\label{forwardModel2}
\end{equation} 
Im Fall der linearen Regression repäsentiert $\mathbf{p} = (\theta_1,\dots,\theta_M)$,
im Fall der Geraden $\mathbf{p} = (\alpha, d)$ und im Fall der Einzelgröße
$\mathbf{p} = \mu$.

Die beiden Annahmen, dass - wie wir letzte Woche bereits bei der linearen Regression
aufgeschrieben hatten - jede einzelne Beobachtung unabhängig und identisch verteilt 
(u.i.v) ist, sind Voraussetzung der Maximum-Likelihood-Methode:
\begin{itemize}
\item Jeder Messpunkt wurde unabhängig von allen anderen gewonnen.
\item Jeder Messpunkt ist identisch verteilt (sie haben die gleiche Streuung).
\end{itemize}
Die gemeinsame Wahrscheinlichkeitsdichte, engl.\ \textsl{joint probability density}, der
Residuen von $j$ voneinander unabhängigen Messungen ist dann das Produkt der
Wahrscheinlichkeitsdichten $p(\varepsilon_j | \mathbf{p}, \sigma)$
jedes Residuums:
\begin{equation}
p(\varepsilon_1,\dots,\varepsilon_J | \mathbf{p}, \sigma) \; = \; 
\prod\limits_{j = 1}^J \, p(\varepsilon_j | \mathbf{p}, \sigma) \; = \; 
 \frac{1}{(\sigma \sqrt{2 \pi})^J} \prod\limits_{j = 1}^J \, 
e^{-\frac{1}{2} \left(\frac{\varepsilon_j}{\sigma}\right)^2}
\end{equation}
und mit Anwendung des Potenzgesetzes ist dies
\begin{equation}
p(\varepsilon_1,\dots,\varepsilon_J | \mathbf{p}, \sigma) \; = \; 
 \frac{1}{(\sigma \sqrt{2 \pi})^J}  \, 
e^{-\frac{1}{2} \sum\limits_{j = 1}^J \left(\frac{\varepsilon_j}{\sigma}\right)^2} .
\label{Likelihood1}
\end{equation}
Für die Maximum-Likelihood-Methode wird diese Wahrscheinlichkeitsdichte sorum gesehen,
dass die in den Residuen steckenden Beobachtungen vorgegeben sind, und die 
Parameter $\mathbf{p}$ durch Maximieren der Verteilung gesucht wird und sich daraus
die Streuung der Residuen $\sigma$ ergibt. Die Residuen sind Funktion der
Beobachtungen $X_{1,j},\dots,X_{N,j}$ und der Parameter $\mathbf{p}$, also
$\varepsilon_j = \varepsilon(X_{1,j},\dots,X_{N,j}, \mathbf{p})$. 
Deshalb formulieren wir die Wahrscheinlichkeitsdichte
$p(\varepsilon_1,\dots,\varepsilon_J | \mathbf{p}, \sigma)$ 
als \textsl{Likelihood} \\
$l(\mathbf{p}, \sigma | \{X_{1,1}, \dots, X_{1,J}\}, \dots, \{X_{N,1}, \dots, X_{N,J}\})$
um und Gl.~(\ref{Likelihood1}) formen wir damit wie folgt um zu
\begin{equation}
l(\mathbf{p}, \sigma | \{X_{1,1}, \dots, X_{1,J}\}, \dots, \{X_{N,1}, \dots, X_{N,J}\}) \; = \; 
 \frac{1}{(\sigma \sqrt{2 \pi})^J}  \, 
e^{-\frac{1}{2} \sum\limits_{j = 1}^J \left(\frac{\varepsilon(X_{1,j},\dots,X_{N,j}, \mathbf{p})}{\sigma}\right)^2} .
\label{Likelihood2}
\end{equation}

Die Maximum-Likelihood-Methode bedeutet: Finde derartige Parameter $\mathbf{p}$, für die
die \textsl{Likelihood} maximal wird
\begin{equation}
\max_{\mathbf{p}} \, \left\{ l(\mathbf{p}) \right\}.
\end{equation}
Wir maximieren die in Gl.~(\ref{Likelihood2}) gegebene \textsl{Likelihood}, indem wir
ihren Exponenten minimieren
\begin{equation}
\min_{\mathbf{p}}\left\{ \sum\limits_{j = 1}^J \left(\frac{\varepsilon(X_{1,j},\dots,X_{N,j},\mathbf{p})}{\sigma}\right)^2  \right\}.
\end{equation}
Hierbei fällt die Varianz, die für alle Residuen und Parameter denselben Wert hat, raus und
das Optimierungsproblem, d.h.\ die Suche des Minimums, reduziert sich
auf das Variieren der Parameter $\mathbf{p}$
\begin{equation}
\min_{\mathbf{p}} \left\{ \sum\limits_{j = 1}^J \, \varepsilon(X_{1,j},\dots,X_{N,j},\mathbf{p})^2  \right\} .
\end{equation}

Die Aussage, dass jeder Messpunkt identisch verteilt ist, also die gleiche Streuverteilung hat,
bedeutet aber nicht unbedingt, dass die Streubreite eine skalare Größe $\sigma$ sein muss,
sondern nur, dass für alle Beobachtungen die identischen Varianzen gelten.

Wenn der Messpunkt wie in Gl.~(\ref{TLSgerade}) ein Vektor aus zwei Größen ist, die nicht
dieselbe physikalische Dimension haben oder zwar dieselbe physikalische Dimension, aber dennoch
unterschiedliche stark streuen, weil die Messprinzipien sich unterscheiden, dann stellt sich
die Darstellung der Residuen komplizierter dar. Ein Beispiel für unterschiedliche physikalische
Dimensionen kann wieder das mit der Messung eines elektrischen Widerstandes sein, bei dem $X_1$ eine
Strommessung und $X_2$ eine Spannungsmessung repräsentieren kann.
Ein Beispiel für dieselbe physikalische Dimension mit unterschiedlichem Streuverhalten kann ein
Oberflächenmessgerät sein, bei dem die Sensorik in vertikaler Richtung zur Messung der Höhen einer
Topographie ein optischer oder taktiler Punktsensor sein kann und die horizontale Achse durch einen
Schlitten mit einem Wegmesssystem in Form eines Glasmaßstabs sein kann.

\begin{figure}
\begin{center}
\includegraphics[width=100mm]{03_vorlesung/media/Vorl3_ResiduenVarianzen.pdf}
\end{center}
\caption{Veranschaulichung für Schätzung von Geradenparametern durch
Minimierung der Summe der Quadrate der Residuen bei verschiedenen Varianzen 
$\sigma_1^2$ und $\sigma_2^2$ der beiden direkten Messgrößen $X_1$ und $X_2$
\label{ResiduenVarianzen}}
\end{figure}
Angenommen Größe $X_1$ zu Gl.~(\ref{TLSgerade}) streue normalverteilt mit $\sigma_1$ und
$X_2$ mit $\sigma_2$, so müsste man beispielsweise die Residuen aus Gl.~(\ref{TLSgerade}) in
Vektorkomponenten parallel zu den die beiden Größen repäsentierenden Achsen zerlegen
\begin{equation}
\vec \varepsilon_j \; = \;
\left(\begin{array}{c}
-\varepsilon_j \sin(\alpha)\\
\varepsilon_j \cos(\alpha)
\end{array}\right) ,
\end{equation}
so dass wir für die Wahrscheinlichkeitsdichte
der $j$-ten Beobachtung den verschiedenen Streubreiten Rechnung tragen können:
\begin{equation}
p(\varepsilon_j | \alpha, d, \sigma_1, \sigma_2) \; \propto \; 
e^{-\frac{1}{2} \left(\frac{\varepsilon_j \sin(\alpha)}{\sigma_1}\right)^2}
\, e^{-\frac{1}{2} \left(\frac{\varepsilon_j \cos(\alpha)}{\sigma_2}\right)^2}
\end{equation}
In der Literatur werden zur Anpassung einer Geraden an zwei Größen
unterschiedlicher Varianz sehr verschiedene Ansätze und Methoden vorgeschlagen.

Die Abweichungen der direkten Messgrößen zu den entsprechenden Werten, also die Residuen,
die bei der Modellschätzung Gl.~(\ref{forwardModel2}) errechnet werden, müssen als
vektorielle Größen behandelt werden, wenn die verschiedenen direkten Messgrößen $X_i$ eine
unterschiedliche Varianz $\sigma_i^2 = \sigma_{i,i}$ oder noch allgemeiner auch
Kovarianzen $\sigma_{i,k}$ aufweisen, die als Kovarianzmatrix
\begin{equation}
\boldsymbol{\Sigma} \; = \;
\left(\begin{array}{ccc}
\sigma_1^2 & \dots & \sigma_{1,N}\\
 & \ddots & \\
\sigma_{N,1} & \dots & \sigma_N^2
\end{array}\right)
\end{equation}
zusammengefasst wird.

Die Wahrscheinlichkeitsdichteverteilung für den Vektor der Residuen der
$j$-ten Beobachtung ist dann
\begin{equation}
p(\vec \varepsilon_j | \mathbf{p}, \boldsymbol{\Sigma}) \; \propto \; 
e^{-\frac{1}{2} \, \vec \varepsilon^\mathsf{T}_j \, \boldsymbol{\Sigma}^{-1} \, \vec \varepsilon_j }
\end{equation}
wobei
\begin{equation}
\vec \varepsilon_j \; = \; 
\left(\begin{array}{c}
X_{1,j}\\
\vdots\\
X_{N,j}
\end{array}\right) \, - \, 
\left(\begin{array}{c}
X_{\mathrm{Modell},1,j}\\
\vdots \\
X_{\mathrm{Modell},N,j}
\end{array}\right) .
\label{Residuen}
\end{equation}
Die \textsl{joined probability density} ist dann entsprechend
\begin{equation}
p(\vec \varepsilon_1,\dots, \vec \varepsilon_J | \mathbf{p}, \boldsymbol{\Sigma}) \; \propto \; 
\prod\limits_{j=1}^J \,
e^{-\frac{1}{2} \, \vec \varepsilon^\mathsf{T}_j \, \boldsymbol{\Sigma}^{-1} \, \vec \varepsilon_j } \; = \;
e^{-\frac{1}{2} \; \sum\limits_{j=1}^J \, \vec \varepsilon^\mathsf{T}_j \, \boldsymbol{\Sigma}^{-1} \, \vec \varepsilon_j } .
\label{LikelihoodKov}
\end{equation}


Für die Lösung eines inversen Problems geht es darum, die Parameter $\mathbf{p}$
für gegebene Beobachtungen $X_{i,j}$ zu finden, die die Wahrscheinlichkeitsdichte
in Gl.~(\ref{LikelihoodKov}) maximieren. Wir schreiben deshalb die Residuenvektoren $\vec \varepsilon_j$ als Funktion
der Beobachtungen $\vec \varepsilon(X_{1,j},\dots,X_{N,j},\mathbf{p})$ auf und verändern die Schreibweise
für die Wahrscheinlichkeit so, dass wir als Likelihood $l$, die eine Funktion der
Variablen $\mathbf{p}$ und $\boldsymbol{\Sigma}$ für gegebene Beobachtungen $(X_{1,j},\dots,X_{N,j})$ ist,
ausdrücken. Gl.~(\ref{LikelihoodKov}) bekommt dann folgende Gestalt
\begin{equation}
l(\mathbf{p}, \boldsymbol{\Sigma} | \{X_{1,1}, \dots, X_{1,J}\}, \dots, \{X_{N,1}, \dots, X_{N,J}\} ) \; \propto \; 
e^{-\frac{1}{2} \; \sum\limits_{j=1}^J \, \vec \varepsilon^\mathsf{T}(X_{1,j},\dots,X_{N,j},\mathbf{p}) \, \boldsymbol{\Sigma}^{-1} \, \vec \varepsilon(X_{1,j},\dots,X_{N,j},\mathbf{p}) } .
\label{LikelihoodKov2}
\end{equation}
Die Kovarianzmatrix ist wie die Residuen Funktion der Parameter und der Beobachtungen,
also $\boldsymbol{\Sigma}(X_{1,j},\dots,X_{N,j},\mathbf{p})$ und
variiert werden die Parameter $\mathbf{p}$.
Zur Maximierung der in Gl.~(\ref{LikelihoodKov2}) gegebenen 
\textsl{Likelihood} wird der Exponent minimiert, was in die Methode der kleinsten Residuenquadratsumme
übergeht, also
\begin{equation}
\min_{\mathbf{p}} \; \left\{ 
 \sum\limits_{j=1}^J \, \vec \varepsilon(X_{1,j},\dots,X_{N,j},\mathbf{p})^\mathsf{T} \, 
\boldsymbol{\Sigma}(X_{1,j},\dots,X_{N,j},\mathbf{p})^{-1} \, \vec \varepsilon(X_{1,j},\dots,X_{N,j},\mathbf{p})_j \right\} .
\label{generalLSmethod}
\end{equation}

\section{Konzept der bayesischen Verfahren zum Lösen inverser Probleme}

Für komplexere Fragestellungen hinsichtlich der Varianzen und hinsichtlich der Möglichkeit,
sukzessive neue Informationen durch weitere Beobachtungen hinzuzufügen und damit die Werte von
interessierenden indirekten Messgrößen immer weiter zu verbessern, stoßen die gängigen Ansätze wie
die Maximum-Likelihood-Methode an gewisse Grenzen. Insbesondere die Möglichkeit, bereits durch
vergangene Optimierungsprozesse gewonnene Parameter durch Gewinnen neuer Beobachtungen zu verändern,
ist nicht Gegenstand der \glqq herkömmlichen\grqq ~Statistik. Mit \glqq herkömmlich\grqq ~ist
an dieser Stelle die \textsl{frequentistische} Statistik gemeint, bei der empirisch aus
Beobachtungen Häufigkeitsverteilungen gewonnen werden, empirische Wahrscheinlichkeitsverteilungen
(Likelihood) berechnet werden, und entsprechend eine Schätzung von Modellparametern erfolgt.
Die lineare Regression ist ein Teilgebiet der \textsl{frequentistischen} Statistik

In der Statistik gibt es dazu zweierlei Blickrichtungen:
\begin{enumerate}
\item In \textbf{frequentistischen Statistik} wird angenommen,
dass der Wert einer indirekten Messgröße unbekannt, aber konstant/ fest ist und deshalb
auch \textsl{wahrer Wert} genannt wird. In Bezug auf die direkt messbaren Größen wird angenommen,
dass sie aufgrund des Mangels an Erkenntnis über alle möglichen Einflüsse und Abläufe im Messprozess
streuen, so dass sie als Zufallsgrößen behandelt werden. Die Behandlung als Zufallsgröße
bedeutet dabei, dass der Wahrscheinlichkeit für eine Beobachtung einen konkreten Wert anzunehmen eine
Wahrscheinlichkeitsdichteverteilung zugrunde gelegt wird.
\begin{equation}
\underbrace{(Y_1, \dots, Y_M)}_{\mathrm{unbek, konst, wahr}} \xrightarrow{\mathrm{Messprozess}}
\underbrace{(X_1, \dots, X_N)}_{\mathrm{Zufallsgroessen}}
\end{equation}
\item Umgekehrt ist die Weise, wie das Zustandekommen der Streuung von Größen gesehen wird,
in der Statistik, die den Satz von Bayes zum Berechnen bedingter Wahrscheinlichkeiten 
verwendet. Dieses Gebiet der Statistik wird wegen der Verwendung des
Satzes von Bayes auch \textbf{bayesische Statistik} genannt.

Hier werden die Beobachtungen der direkten Größen, als konkrete, feste Werte eingesetzt,
um die Erkenntnis über die zu bestimmende indirekte Größe zu überprüfen bzw.\ zu vermehren.
Die Vorstellung ist, dass durch den Mangel an Erkenntnis die indirekten Größen als
Zufallsgrößen zu behandeln sind. Es wird nun also nicht mehr nur eine Likelihood-Verteilung
berechnet, deren Maximum gesucht wird. Sondern es wird eine Kombination der Likelihood mit
einer Wahrscheinlichkeitsdichteverteilung,
die eine {\`a} priori Annahme über die indirekten Messgrößen darstellt, berechnet und der
Erwartungswert (das erste statistische Moment) und die Varianz (das zweite statistische Moment)
dieser kombinierten Verteilungsdichte ermittelt.

Dabei repräsentieren die Wahrscheinlichkeiten für die zu erwartenden Beobachtungen eines Parameters
(einer indirekten Messgröße), 
den Grad der Erkenntnis, vernünftiger Glaubwürdigkeit, über die indirekte Messgröße.
In der englischsprachigen Literatur wird dies \textsl{Degree of Belief} genannt.

Vielleicht kann man sich diese Denkweise so vorstellen wie die Vorgehensweise eines Detektivs
oder Kriminalkommissars beim Sammeln von immer mehr Indizien zum Aufklären eines Falls.
\begin{equation}
\underbrace{(X_1, \dots, X_N)}_{\mathrm{Beobachtungen}} \xrightarrow{\mathrm{inverses \; Problem}}
\underbrace{(Y_1, \dots, Y_M)}_{\mathrm{Zufallsgroessen}} 
\end{equation}
Die Erkenntnis über die indirekten Größen (Modellparameter $Y_1, \dots, Y_M$) wird mit jeder
neuen Messkampagne $\kappa$ revidiert
\begin{equation}
\arraycolsep=2.4pt\def\arraystretch{2}
\left.
\begin{array}{l}
\underbrace{(X_1, \dots, X_N)}_{\mathrm{neue~Beobachtungen}}\\
\underbrace{(Y_1, \dots, Y_M)_{\kappa-1}}_{\mathrm{Zufallsgroessen, vorher}} 
\end{array}\right\}
 \xrightarrow{\mathrm{inverses \; Problem}}
\underbrace{(Y_1, \dots, Y_M)_{\kappa}}_{\mathrm{Zufallsgroessen}} 
\end{equation}
\end{enumerate}
Da wir wie vorher detailiert dargelegt die indirekten Größen durch approximative Modellparameter ersetzten,
also $Y_m \approx P_m$, sind es die Schätzungen zu den Parametern $\mathbf{p} = (P_1,\dots,P_M)$, die
sozusagen \glqq\textsl{upgedated}\grqq ~werden.
\begin{equation}
\arraycolsep=2.4pt\def\arraystretch{2}
\left.
\begin{array}{l}
\underbrace{(X_1, \dots, X_N)}_{\mathrm{neue~Beobachtung}}\\
\underbrace{(P_1, \sigma^2_1, \dots, P_M, \sigma^2_M)_{\kappa-1}}_{\mathrm{Zufallsgroesse, vorher}} 
\end{array}\right\}
 \xrightarrow{\mathrm{inverses \; Problem}}
\underbrace{(P_1, \sigma^2_1, \dots, P_M, \sigma^2_M)_{\kappa}}_{\mathrm{Zufallsgroesse}} 
\end{equation}

Wir betrachten wie in Gl.~(\ref{oneQuantityOnly1}) den einfachsten Fall einer Größe,
die wir wie in Gl.~(\ref{oneQuantityOnly1}) auch hier als Modellparameter $P = \mu$, der
eine indirekte Messgröße $Y$ repräsentieren soll, aufschreiben.
Die Größe $\mu$ ist aus einer Stichprobe zu schätzen.
Als {\`a} priori Information seien folgende Angaben bekannt:
\begin{itemize}
\item Der {\`a} priori Schätzwert der Modellgröße $\mu$ sei $y_0$.
\item Der {\`a} priori Schätzwert seiner Varianz $\sigma^2$ sei $s^2_0$.
\item Diese Größe sei normalverteilt, also verwenden wir als
Verteilungsdichtefunktion $p$ die Gaußverteilung.
\end{itemize}
Die neue Stichprobe $\{X_{1,1}, \dots, X_{1,J}\}$ sei vom Umfang deutlich kleiner, so dass
für die Streuung der Varianz die $\chi^2$-Verteilung $p_{\chi^2,\nu}$
für $\nu = J-1$ Freiheitsgrade verwendet wird. Hierzu müssen wir im Stoff vorgreifen.
Diese Verteilungsdichtefunktion werden wir in der 5.\ Vorlesung behandeln.
Sie wird verwendet als Verteilungsdichte für Varianzen und ist eine schiefsymmetrische
Verteilung mit längerem Ausläufer zu größeren Werten. Je kleiner der Stichprobenumfang,
desto schiefer die Verteilung und ausgeprägter die Ausläufer.

Die gesamte Wahrscheinlichkeitsdichteverteilung $p(Y,\sigma)$ für die indirekte Messgröße
$Y$ bzw.\ deren Approximation als Modellparameter $P = \mu$ mit Streuung $\sigma$ wird als Produkt
folgender Wahrscheinlichkeiten berechnet,
\begin{itemize}
\item der Likelihood $p_\mathrm{L}$, 
\item der Verteilungsdichte $p_\mathcal{N}(y | y_0, s_0)$ der Größe $\mu$ aus den {\`a} priori Informationen,
\item der Verteilungsdichte $p_{\chi^2,\nu}(s)$ der Varianz $\sigma^2$ dieser Größe.
\end{itemize}
Die zu ermittelnde, bedingte Wahrscheinlichkeitsdichte wird so interpretiert, dass die Verteilung Funktion
der Variablen $\mu$ und $\sigma$ ist, gegeben die Beobachtungswerte der Stichprobe. Die Likelihood wird
dabei betrachtet als die bedingte Wahrscheinlichkeitsdichte $p_\mathrm{L}$ der
direkten Messgröße $X_1$ gegeben die Modellparameter $\mu$ und $\sigma$:
\begin{equation}
p_\mathrm{L}(\{X_{1,1}, \dots, X_{1,J}\} | \mu, \sigma) \; = \;
\prod\limits_{j=1}^J \frac{1}{\sqrt{2 \pi} \, \sigma}
 e^{- \frac{1}{2} \, \left( \frac{X_{1,j} - \mu}{\sigma} \right)^2 }  \; = \;
l(\mu, \sigma | \{X_{1,1}, \dots, X_{1,J}\}).
\end{equation}
Die Varianz $\sigma^2$ wird gemäß der $\chi^2$-Verteilung variert. Das Variieren der Varianz
bzw.\ deren Wurzel $\sigma$ symbolisieren wir durch den Gebrauch der Variablen $s$.
Das Variieren des Modellparameters $\mu$ symbolisieren wir durch den Gebrauch der Variablen $y$.
Der Parameter $\mu$ wird ebenfalls variiert gemäß der Gaußverteilung, wir verwenden folgende
Likelihood:
\begin{equation}
p_\mathrm{L}(\{X_{1,1}, \dots, X_{1,J}\} | y, s) \; = \;
\prod\limits_{j=1}^J \frac{1}{\sqrt{2 \pi} \, s}
 e^{- \frac{1}{2} \, \left( \frac{X_{1,j} - y}{s} \right)^2 }  \; = \;
l(y, s | \{X_{1,1}, \dots, X_{1,J}\}).
\end{equation}

\begin{figure}
\begin{center}
\includegraphics[width=100mm]{03_vorlesung/media/understand_bayes_mean_posteriormatrix.pdf}
\caption{\label{posteriormatrix} Posterior-Wahrscheinlichkeitsdichte als Funktion
der beiden zu schätzenden Größen $y$ und $s$.}
\end{center}
\end{figure}
Das Produkt ist die Wahrscheinlichkeit des Modellparameters und dessen Varianz gegeben
die Stichprobe $\{X_{1,1}, \dots, X_{1,J}\}$ und die {\`a} priori Informationen $y_0, s_0$
\begin{equation}
p(y, s | \{X_{1,1}, \dots, X_{1,J}\}, y_0, s_0) \; = \; C \,
p_\mathrm{L}(\{X_{1,1}, \dots, X_{1,J}\} | y, s) \; p_\mathcal{N}(y | y_0, s_0) \; p_{\chi^2,\nu}(s)
\label{ProduktWahrscheinlichkeiten}
\end{equation}
mit $C$ als Normierungsfaktor derart zu wählen, dass die integrierte Wahrscheinlichkeit Eins ist, d.h.
$$
\int\limits_{-\infty}^\infty  \int\limits_0^\infty \; p(y, s | \{X_{1,1}, \dots, X_{1,J}\}, y_0, s_0) \;
\operatorname{d}s \, \operatorname{d}y \; = \; 1 .
$$
Die Verteilungsdichte $p(y, s | \{X_{1,1}, \dots, X_{1,J}\}, y_0, s_0)$ ist Funktion der
Variablen $y$ und $s$ mit vorgegebenen Parametern 
(festen Werten) $\{X_{1,1}, \dots, X_{1,J}\}$, $y_0, s_0$, wie es beispielhaft in 
Abb.~\ref{posteriormatrix} dargestellt wird.

Die Wahrscheinlichkeitsdichteverteilung
$p_\mathcal{N}(y | y_0, s_0)$ wird \textsl{Prior} genannt und die
Wahr\-schein\-lich\-keits\-dichte\-ver\-teilung $p(y, s | \{X_{1,1}, \dots, X_{1,J}\}, y_0, s_0)$
wird \textsl{Posterior} genannt.

Wir integrieren Gl.~(\ref{ProduktWahrscheinlichkeiten}) über $s$ um eine 
Wahrscheinlichkeits\-dichte\-verteilung zu gewinnen, die nur noch Funktion von $y$ ist
\begin{equation}
p(y | \{X_{1,1}, \dots, X_{1,J}\}, y_0, s_0)  \; = \;
\int\limits_0^\infty p(y, s | \{X_{1,1}, \dots, X_{1,J}\}, y_0, s_0) \operatorname{d}s
\label{RandverteilungPosterior}
\end{equation}
Diese Verteilung wird \textsl{Randverteilung} oder \textsl{Marginalverteilung} genannt.
Allgemeiner gilt: Gegeben zwei Zufallsgrößen $A$ und $B$ mit gemeinsamer Verteilungsdichte
$p(A, B)$ dann heißen die Verteilungen der einzelnen Zufallsgrößen
$A$ und $B$ die Randverteilungen des Zufallsvektors $(A, B)$.

Als Schätzwert für $Y$ berechnen wir den Erwartungswert des Modellparameters $\mu$
durch Integration über alle Werte $y$ gewichtet mit der Wahrscheinlichkeitsdichte\\
$p(y | \{X_{1,1}, \dots, X_{1,J}\}, y_0, s_0)$ aus Gl.~(\ref{RandverteilungPosterior})
\begin{equation}
y_1 \; = \; \int\limits_{-\infty}^\infty \, y \, p(y | \{X_{1,1}, \dots, X_{1,J}\}, y_0, s_0) 
\operatorname{d}y
\end{equation}
wobei wir $y_1$ mit Index $1$ schreiben, um anzuzeigen, dass dies die Revision der Schätzung des 
Modellparameters $\mu \approx Y$ gegenüber vorheriger Kenntnis mit Schätzwert $y_0$ ist.

Zu einem \textsl{Messergebnis} gehört jeweils ein Intervall, das ein Maß für die Unsicherheit
des Wertes/ der Werte der Messgröße ist, siehe [VIM 2.9]

\begin{quote}
\textbf{Messergebnis}

Menge von Größenwerten, die einer Messgröße zugewiesen sind, zusammen mit jeglicher
verfügbarer relevanter Information

ANMERKUNG 1 Ein \textsl{Messergebnis} enthält im Allgemeinen \glqq relevante Information\grqq ~über
die Menge der Größenwerte, von denen einige repräsentativer für die Messgröße sein können als andere.
Dies kann in Form einer Wahrscheinlichkeitsdichtefunktion ausgedrückt werden.

ANMERKUNG 2 Ein \textsl{Messergebnis} wird im Allgemeinen
als ein einziger Messwert und eine \textsl{Messunsicherheit}
ausgedrückt. Wird die Messunsicherheit für einige
Zwecke als vernachlässigbar angesehen, kann das
Messergebnis als ein einziger Messwert ausgedrückt
werden. In vielen Bereichen ist dies die übliche Art, ein
Messergebnis auszudrücken.

ANMERKUNG 3 In der traditionellen Literatur und in der
vorhergehenden Ausgabe des VIM war das Messergebnis
als ein Wert definiert, der einer Messgröße zugewiesen
ist, und so erklärt, dass er eine Anzeige oder ein
unkorrigiertes oder ein korrigiertes Ergebnis bedeutet, je
nach Kontext.
\end{quote}

Mit der in Anmerkung~1 angesprochenen Wahrscheinlichkeitsdichtefunktion sind Verteilungen wie
die in den Gln.~(\ref{Likelihood2}) und (\ref{LikelihoodKov2}) vorgestellen Likelihoods oder
der in Gl.~(\ref{RandverteilungPosterior}) vorgestellten Posterior
mit $p(y | \{X_{1,1}, \dots, X_{1,J}\}, y_0, s_0)$ gemeint. Die Likelihood wird
für kleine Stich\-proben\-um\-fänge ($N < 100$) anstelle durch eine Gaußverteilung durch eine Verteilung 
repräsentiert, deren Charakteristik im Kurvenverlauf
überhöhter und mit länger auslaufenden Rändern ist. Sie wird $t$-Verteilung genannt.
Wir werden später in der 5.\ Vorlesung auf diesen Verteilungtyp zurück kommen.

Allgemein betrachten wir für beide Fälle eine Wahrscheinlichkeitsdichtefunktion $p \! : y \mapsto p(y)$.
Der Definitionsbereich für $y$ reicht von minus bis plus Unendlich reicht. Von Interesse ist der Kernbereich
der Dichteverteilung für eine spezifizierte Wahrscheinlichkeit $1-\alpha$, beispielsweise
$1-\alpha = 0.95$ oder $0.90$ oder so.
Dies ist die Wahrscheinlichkeit einer Größe, einen Messwert im Bereich (Intervall) $[y_\mathrm{min}, y_\mathrm{max}]$,
anzunehmen
\begin{equation}
1 \, - \, \alpha \; = \; 
\int\limits_{y_\mathrm{min}}^{y_\mathrm{max}} p(y) 
\operatorname{d}y .
\label{UeberdeckungWahrscheinlichkeit}
\end{equation}
Die Breite des Intervalls gibt dann die \textsl{Messunsicherheit} an.

Das Intervall $[y_\mathrm{min}, y_\mathrm{max}]$, zu dem die Fläche $1 - \alpha$ unter der die
Verteilungsdichte $p(y)$ repräsentierenden Kurve gehört, wird \textsl{Überdeckungsintervall} genannt.
Es ist der verallgemeinerte Begriff aus der Metrologie für das, was in der
\textsl{frequentistischen} Statistik \textsl{Vertrauensintervall},
engl.\  \textsl{Confidence Interval}, und in der \textsl{bayesischen} Statistik 
\textsl{Glaubwürdigkeitsintervall}, engl.\ \textsl{Credible Interval},
heißt. Während der Begriff \textsl{Vertrauensintervall} in der deutschsprachigen
Literatur üblich ist, wird anstelle des Begriffs \textsl{Glaubwürdigkeitsintervall} üblicherweise
auch in der deutschsprachigen Literatur der Begriff \textsl{Credible Interval} verwendet.

Die Verwendung unterschiedlicher Bezeichnungen, \textsl{Confidence Interval} und
\textsl{Credible Interval}, sollen die Unterschiedlichkeit der Vorstellungen
über den Charakter einer indirekten Messgröße $Y$ zum Ausdruck bringen.
Die Unterschiedlichkeit in der Vorstellung von einer indirekten Messgröße $Y$ besteht darin,
dass im Fall der \textsl{bayesischen} Statistik
die indirekte Messgröße $Y$ als Größe, die intrinsisch eine Zufallsgröße ist, betrachtet
wird. Im Fall der \textsl{frequentistischen} Statistik wird $Y$ als eine Größe betrachtet,
die einen festen, wahren Wert hat, der aber nicht zugänglich ist. Nur der
Modellparameter, der eine indirekte Messgröße approximiert und der indirekt aus anderen 
Zufallsgrößen gewonnen wird, wird als daraus resultierend einer Streuung unterliegend betrachtet.

Die Wahrscheinlichkeit $1 - \alpha$ wird in der \textsl{frequentistischen} Statistik
\textsl{Vertrauensniveau} genannt. Die beiden Flächen unter den
Ausläufern der Dichteverteilung stellt eine Wahrscheinlichkeit $\alpha$ dar, die in der
\textsl{frequentistischen} Statistik \textsl{Signifikanzniveau} genannt wird.

Im folgenden werden wir sehen, wie eine \textsl{Messunsicherheit} im Rahmen der
\textsl{bayesischen} Statistik gewonnen wird.
Die Grenzen des \textsl{Credible Interval} $[y_\mathrm{min}, y_\mathrm{max}]$ bilden die
Integrationsgrenzen $y_\mathrm{min}$ und $y_\mathrm{max}$ der \textsl{Posterior}, so dass
\begin{equation}
1 \, - \, \alpha \; = \; 
\int\limits_{y_\mathrm{min}}^{y_\mathrm{max}} p(y | \{X_{1,1}, \dots, X_{1,J}\}, y_0, s_0) 
\operatorname{d}y .
\label{UeberdeckungPosterior}
\end{equation}
Die Integrationsgrenzen werden über die Umkehrfunktion der kumulativen Verteilung $P$ berechnet.
Die kumulative Verteilung $P$ ist
\begin{equation}
P(y) \; = \; \int\limits_{-\infty}^{y} p(y^\prime | \{X_{1,1}, \dots, X_{1,J}\}, y_0, s_0) 
\operatorname{d}y^\prime .
\end{equation}
Die Umkehrfunktion schreiben wir symbolisch als $P^{-1}$.
Wir berechnen für das \textsl{Credible Interval}
\begin{equation}
y_\mathrm{min} \, = \, P^{-1}(\frac{\alpha}{2}) \qquad \mathrm{und} \qquad
y_\mathrm{max} \, = \, P^{-1}(\frac{1-\alpha}{2}).
\end{equation}
\begin{figure}
\begin{center}
\includegraphics[width=80mm]{03_vorlesung/media/understand_bayes_mean_posteriormarginal.pdf}
\hspace{5mm}
\includegraphics[width=80mm]{03_vorlesung/media/understand_bayes_mean_cumposterior.pdf}
\caption{\label{posteriorCredible}\textsl{Links:} Die blaue Kurve stellt die
Randverteilung der Posterior-Wahrscheinlichkeitsdichte als Funktion
der beiden zu schätzenden Größen $Y$ mit \textsl{Credible Interval} dar und die
rot gestrichelte Kurve die Student-t-Verteilung mit Vertrauensintervall.
\textsl{Rechts:} Kumulierte Randverteilung der Posterior-Wahrscheinlichkeitsdichte, deren
Umkehrfunktion verwendet wird, um die Intervallgrenzen des \textsl{Credible Interval}s zu ermitteln.}
\end{center}
\end{figure}
Abb.~\ref{posteriorCredible} links zeigt im Vergleich folgende Verteilungsdichten
\begin{itemize}
\item die Posterior als Funktion des Parameters
$y$ mit einem \textsl{Credible Interval} für eine Wahrscheinlichkeit von
$1 - \alpha = 0.95$ (blaue, durchgezogene Kurve und blaue, durchgezogene Linien)
\item die $t$-Verteilung (rote, gestrichelte Kurve), die sich für die in dem
graphisch dargestellten Beispiel verwendeten Stichprobe mit Stichprobenumfang $J = 7$, folglich
$\nu = J - 1 = 6$ Freiheitsgraden ergeben hat, sowie das Vertrauensintervall (rote, gestrichelte Linien),
das aus dem Mittelwert der Stichprobe
und der empirischen Standardabweichung des Mittelwerts multipliziert mit dem
t-Quantil gewonnen wurde. Mit dem Begriff t-Quantil werden die Integrationsgrenzen dieser Verteilung
zu vorgegebenen Wahrscheinlichkeiten $\frac{\alpha}{2}$ und $1 - \frac{\alpha}{2}$ bezeichnet.
\end{itemize}

Abb.~\ref{posteriorCredible} rechts zeigt die kumulierte Posterior, aus deren Umkehrfunktion
zu den Wahrscheinlichkeiten $\frac{\alpha}{2}$ und $1 - \frac{\alpha}{2}$ die
Intervallgrenzen des \textsl{Credible Interval}s gewonnen werden.

Die Ermittlung der \textsl{Messunsicherheit} im Rahmen der
\textsl{frequentistischen} Statistik unter Verwendung der $t$-Verteilung
wird in den kommenden Wochen detailiert und mit Beispielen dargelegt werden.
Sie wird einen großen Teil dieser Vorlesungsreihe ausmachen und Klausurrelevanz haben.

